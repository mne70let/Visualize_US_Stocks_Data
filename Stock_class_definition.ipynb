{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Stock_class_definition.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOXRBfz9u3hDVDyzBAuUGhX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"g1YLe0__sY2S","colab":{"base_uri":"https://localhost:8080/","height":371},"executionInfo":{"status":"error","timestamp":1605824647277,"user_tz":-660,"elapsed":1633,"user":{"displayName":"Sergey Pesotskiy","photoUrl":"","userId":"07249618744860595257"}},"outputId":"0efe3c2a-c278-4f2c-a9f6-2efea3c33e81"},"source":["#--------------------------\n","#Stock class definition\n","#--------------------------\n","class stock_class:\n","  'This is a class to work download stocks'\n","  #Key class attributes\n","  fundamentals = pd.DataFrame() #fundamentals dynamics\n","  hist_price_div = pd.DataFrame() #price and divs dynamics\n","  profile = pd.DataFrame() #company profile\n","  n_api=0 #num of api requests\n","\n","  #Parameters required at class creation\n","  def __init__(self, ticker, benchmark = False):\n","    self.ticker=ticker\n","    self.benchmark=benchmark\n","    #getting fundamentals and prices as class attributes using functions (methods) defined below:\n","    self.hist_price_div = self.read_from_gd()[0]  \n","    self.fundamentals = self.read_from_gd()[1]\n","    self.profile = self.read_from_gd()[2]\n","\n","    #If no profile of gdrive - get it from yahoo finance\n","    if (self.profile.empty == True) and (self.benchmark == False):\n","      self.profile=pd.DataFrame(self.read_company_info_from_yahoo())\n","      self.profile.to_csv(self.ticker+ '_profile.csv')\n","      shutil.copy(self.ticker+ '_profile.csv', gdfolder + self.ticker+ '_profile.csv')\n","\n","    #If no price&divs data on gdrive - do request to API\n","    if (self.hist_price_div.empty == True):\n","      #Reading from API\n","      hist_price=self.read_from_api(self.hist_price_url()) #local variable\n","      #to minimize number of api requets if error\n","      if hist_price.empty == False:\n","        ##Working further with price and divs\n","        hist_divs=self.read_from_api(self.hist_divs_url())\n","        hist_price.drop(hist_price.columns.difference(['close']), 1, inplace=True)#drop all except\n","        if hist_divs.empty == False:\n","          hist_divs.drop(hist_divs.columns.difference(['adjDividend']), 1, inplace=True)#drop all except\n","        else: #fictios 0 div entry to make other scripts work for no div shares\n","          hist_divs=pd.DataFrame()\n","          hist_divs=pd.DataFrame([{'date': '2020-01-02', 'adjDividend': 0}])\n","          hist_divs['date'] = pd.to_datetime(hist_divs['date'])\n","          hist_divs.set_index('date', inplace=True)\n","        self.hist_price_div = pd.concat([hist_price, hist_divs], axis =1)\n","        self.hist_price_div.index=pd.to_datetime(self.hist_price_div.index) #conversion to timestamp\n","        self.hist_price_div['adjDividend'] = self.hist_price_div['adjDividend'].fillna(0)\n","        self.hist_price_div.to_csv(self.ticker+ '_hist_price_div.csv')\n","        shutil.copy(self.ticker+ '_hist_price_div.csv', gdfolder + self.ticker+ '_hist_price_div.csv')\n","        \n","        ##Working with profile and fundamentals dynamics (not for benchmarks):\n","        if self.benchmark == False:\n","          ratios=self.read_from_api(self.ratios_url())\n","          ratios_ttm=self.read_from_api(self.ratios_ttm_url())\n","          key_metrics=self.read_from_api(self.key_metrics_url())\n","          key_metrics_ttm=self.read_from_api(self.key_metrics_ttm_url())      \n","          self.fundamentals = pd.concat([ratios, key_metrics], axis =1)\n","          self.fundamentals = self.fundamentals.loc[:,~self.fundamentals.columns.duplicated()] #removes duplicated columns\n","          #Combining TTM (as a first row) with other annual fundamentals     \n","          fundamentals_ttm = pd.concat([ratios_ttm, key_metrics_ttm], axis =1)\n","          fundamentals_ttm.insert(0, \"date\", [pricedatemax], False) \n","          fundamentals_ttm.insert(0, \"symbol\", self.ticker , False)\n","          fundamentals_ttm['date'] = pd.to_datetime(fundamentals_ttm['date'])\n","          fundamentals_ttm.set_index('date', inplace=True)\n","          for column in fundamentals_ttm.columns:\n","            fundamentals_ttm.rename({column:column.replace('TTM','')}, axis='columns',inplace=True)\n","          fundamentals_ttm = fundamentals_ttm.loc[:,~fundamentals_ttm.columns.duplicated()] #removes duplicated columns\n","          self.fundamentals = pd.concat([self.fundamentals, fundamentals_ttm], axis =0, join='inner')\n","          self.fundamentals.sort_index(inplace=True)\n","          self.fundamentals.index=pd.to_datetime(self.fundamentals.index) #conversion to timestamp\n","        self.fundamentals.to_csv(self.ticker+ '_fundamentals.csv')\n","        shutil.copy(self.ticker+ '_fundamentals.csv', gdfolder + self.ticker+ '_fundamentals.csv')      \n","        self.n_api=self.n_api+6\n","      else:\n","        print('Ticker not found or num of API requests has been exceeded: ' + self.ticker)\n","\n","  #Defining urls\n","  def hist_price_url (self):          \n","    return source['site'] + \"historical-price-full/\"+self.ticker+\"?from=\" + pricedatemin + \"&to=\" + pricedatemax + \"&apikey=\"+source['apikey']\n","  def hist_divs_url (self):\n","    return source['site'] + \"historical-price-full/stock_dividend/\"+self.ticker+\"?from=\" + pricedatemin + \"&to=\" + pricedatemax + \"&apikey=\"+source['apikey']\n"," \n","  def ratios_url (self):\n","    return source['site'] + \"ratios/\"+self.ticker+\"?limit=\" + str(yrs) + \"&apikey=\"+source['apikey']\n","  def ratios_ttm_url (self):\n","    return source['site'] + \"ratios-ttm/\"+self.ticker+\"?&apikey=\"+source['apikey']\n","  def key_metrics_url (self):\n","    return source['site'] + \"key-metrics/\"+self.ticker+\"?limit=\" + str(yrs) + \"&apikey=\"+source['apikey']\n","  def key_metrics_ttm_url (self):\n","    return source['site'] + \"key-metrics-ttm/\"+self.ticker+\"?&apikey=\"+source['apikey']\n","  def growth_url (self):\n","    return source['site'] + \"financial-growth/\"+self.ticker+\"?limit=\" + str(yrs) + \"&apikey=\"+source['apikey']\n","  def company_profile_url (self):\n","    return \"https://finance.yahoo.com/quote/\"+self.ticker+\"/profile?p=\"+self.ticker\n","  def company_holders_url (self):\n","    return \"https://finance.yahoo.com/quote/\"+self.ticker+\"/holders?p=\"+self.ticker\n","  def company_summary_url (self):\n","    return \"https://finance.yahoo.com/quote/\"+self.ticker+\"?p=\"+self.ticker\n","\n","  #Function to read data from API to dataframe\n","  def read_from_api(self, url):\n","    try:\n","      data = urllib.request.urlopen(url, context=ctx).read()\n","      info = json.loads(data)\n","      if \"historical\" in url:\n","        info = pd.DataFrame(info['historical'])\n","      else:\n","        info = pd.DataFrame(info)      \n","      if 'date' in info: \n","        info['date'] = pd.to_datetime(info['date'])\n","        info.set_index('date', inplace=True)\n","      return info \n","    except:\n","      info = pd.DataFrame()\n","      return info\n","\n","  #Function to get company info\n","  def read_company_info_from_yahoo (self):\n","    try:\n","      html = urllib.request.urlopen(self.company_profile_url(), context=ctx).read()\n","      soup = BeautifulSoup(html, 'html.parser')\n","      tags = soup('span',{'class': 'Fw(600)'})\n","      tagsd = soup('p',{'Mt(15px) Lh(1.6)'})\n","      html = urllib.request.urlopen(self.company_holders_url(), context=ctx).read()\n","      soup = BeautifulSoup(html, 'html.parser')\n","      tagh = soup('td',{'class': 'Py(10px) Va(m) Fw(600) W(15%)'})\n","      return [{'symbol': self.ticker, 'Sector': tags[0].text, 'Industry': tags[1].text, 'NumEmployees': tags[2].text , 'InstitutionalHolders': tagh[1].text , 'InsideHolders': tagh[0].text , 'Description' : tagsd[0].text}]\n","    except:\n","      return [{'symbol': '', 'Sector': '', 'Industry': '', 'NumEmployees': '' , 'InstitutionalHolders': '' , 'InsideHolders': '', 'Description' : ''}]\n","\n","  #Function to get ttm values from yahoo\n","  def get_ttm_from_yahoo (self):\n","    try:\n","      tgt_website = 'https://sg.finance.yahoo.com/quote/' + self.ticker + '/key-statistics?p=' + self.ticker\n","      tgt_website = r\"{}\".format(tgt_website)\n","      # The web page is make up of several html table. By calling read_html function.\n","      # all the tables are retrieved in dataframe format.\n","      # Next is to append all the table and transpose it to give a nice one row data.\n","      df_list = pd.read_html(tgt_website)\n","      result_df = df_list[0]\n","      for df in df_list[1:]:\n","          result_df = result_df.append(df)\n","      # The data is in column format.\n","      # Transpose the result to make all data in single row\n","      result_df=result_df.set_index(0).T\n","      try: # to avoid errors if NaN\n","        result_df['Forward annual dividend yield 4'][1]=result_df['Forward annual dividend yield 4'][1].replace('%','')\n","      except: \n","        result_df['Forward annual dividend yield 4'][1]=0      \n","      result_df.loc[1]=pd.to_numeric(result_df.loc[1], errors='coerce')\n","      #result_df['52-week high 3'][1]\n","      #result_df['52-week high 3'][1]\n","      #result_df['52-week high 3'][1]\n","      #result_df['Diluted EPS (ttm)'][1]\n","      #result_df['Forward annual dividend yield 4'][1]      \n","      return [ {'date': date.today(), 'PEttm': result_df['Trailing P/E'][1], 'EPS': result_df['Diluted EPS (ttm)'][1], 'DivYield': (result_df['Forward annual dividend yield 4'][1])/100, 'RevPerShare': result_df['Revenue per share (ttm)'][1]} ]\n","    except:\n","      return [ {'date': date.today(), 'PEttm': '', 'EPS': '', 'DivYield': '', 'RevPerShare': '' } ]\n","\n","  #Function to read data from google drive\n","  def read_from_gd (self):\n","    #1 getting hist_price_div\n","    try:\n","      shutil.copy(gdfolder + self.ticker+ '_hist_price_div.csv', self.ticker+ '_hist_price_div.csv')\n","      hist_price_div = pd.read_csv(self.ticker+ '_hist_price_div.csv', index_col=0)\n","      hist_price_div.index=pd.to_datetime(hist_price_div.index)\n","    except:\n","      hist_price_div = pd.DataFrame()\n","    # 2 Getting fundamentals    \n","    try:\n","      shutil.copy(gdfolder + self.ticker+ '_fundamentals.csv', self.ticker+ '_fundamentals.csv')\n","      fundamentals = pd.read_csv(self.ticker+ '_fundamentals.csv', index_col=0)\n","      fundamentals.index=pd.to_datetime(fundamentals.index) #conversion to timestamp\n","    except:\n","      fundamentals = pd.DataFrame()\n","    # 3 Getting company profile    \n","    try:\n","      shutil.copy(gdfolder + self.ticker+ '_profile.csv', self.ticker+ '_profile.csv')\n","      profile = pd.read_csv(self.ticker+ '_profile.csv', index_col=0)\n","      #profile.index=pd.to_datetime(profile.index) #conversion to timestamp\n","    except:\n","      profile = pd.DataFrame()\n","    return [hist_price_div, fundamentals, profile] \n","\n","  def limit_dataframes (self, datemin, datemax):\n","    try:\n","      self.hist_price_div=self.hist_price_div[datemin:datemax]\n","      self.fundamentals=self.fundamentals[datemin:datemax]  \n","    except:\n","      pass\n","    \n","  #Function to get CAGR based on price changes only\n","  def cagr_price (self, datemin=pricedatemin, datemax=pricedatemax):\n","    try:\n","      tstep1=self.hist_price_div.index.get_loc(datemin, method='nearest')\n","      tstep2=self.hist_price_div.index.get_loc(datemax, method='nearest')\n","      delta=(self.hist_price_div.index[tstep2]-self.hist_price_div.index[tstep1]).days\n","      cagr_price=(self.hist_price_div.iloc[tstep2,0]/self.hist_price_div.iloc[tstep1,0])**(365/delta)-1\n","      return cagr_price\n","    except:\n","      print(self.ticker + ': error with CAGR calc')\n","\n","  #Function to get CAGR with divs reinvested\n","  def cagr_price_div (self, datemin=pricedatemin, datemax=pricedatemax):\n","    try:\n","      #Adding row to calc CAGR\n","      self.hist_price_div['divs_reinv'] = self.hist_price_div['close']\n","      tstep1=self.hist_price_div.index.get_loc(datemin, method='nearest')\n","      tstep2=self.hist_price_div.index.get_loc(datemax, method='nearest')\n","      i=tstep1\n","      while i <= tstep2:\n","        self.hist_price_div.iloc[i,2] = self.hist_price_div.iloc[i-1,2]*self.hist_price_div.iloc[i,0]/self.hist_price_div.iloc[i-1,0]+self.hist_price_div.iloc[i,1]\n","        i=i+1\n","      delta=(self.hist_price_div.index[tstep2]-self.hist_price_div.index[tstep1]).days\n","      cagr_price_div=(self.hist_price_div.iloc[tstep2,2]/self.hist_price_div.iloc[tstep1,2])**(365/delta)-1\n","      return cagr_price_div\n","    except:\n","      print(self.ticker + ': error with CAGR calc')\n","\n","  def growth (self, param, years):\n","    try:\n","      self.fundamentals\n","      g=list()\n","      i=len(self.fundamentals.index)-1      \n","      while i >= 1:\n","        g.append(self.fundamentals[param][i]/self.fundamentals[param][i-1]-1)\n","        i=i-1\n","      if years == 3:\n","        ret=sum(g[1:4])/3\n","      elif years ==1:\n","        ret=g[0]\n","      else:\n","        ret=''\n","      return ret\n","    except:\n","      return ''\n","\n","  def average (self, param, years):\n","    try:\n","      l=len(self.fundamentals.index)\n","      ret = sum(self.fundamentals[param][(l-years):l]) / years\n","      return ret\n","    except:\n","      return ''"],"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-20b49d32cc97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Stock class definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#--------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mstock_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;34m'This is a class to work download stocks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#Key class attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-20b49d32cc97>\u001b[0m in \u001b[0;36mstock_class\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;34m'This is a class to work download stocks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#Key class attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mfundamentals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fundamentals dynamics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mhist_price_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#price and divs dynamics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#company profile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]}]}